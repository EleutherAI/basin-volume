{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import torch\n",
    "import optax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_t = torch.randn(10).cuda()\n",
    "m_t = torch.randn(5, 20).cuda()\n",
    "\n",
    "x_j = jax.dlpack.from_dlpack(x_t)\n",
    "m_j = jax.dlpack.from_dlpack(m_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.7310, -1.4227,  0.5018], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t[7:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([49])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_t[m_t > 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0, dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "sum(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1223795\n",
      "tensor(1.1224)\n"
     ]
    }
   ],
   "source": [
    "print(jnp.sqrt(jnp.mean(x_j**2)))\n",
    "print(torch.sqrt(torch.mean(x_t**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.09618212 0.05916178 0.11385506 0.04406569 0.0134258  0.02512521\n",
      "  0.07545603 0.04197667 0.00796455 0.02775626 0.03632289 0.01237059\n",
      "  0.0069953  0.06285039 0.15638438 0.04885745 0.01784063 0.10412237\n",
      "  0.02922109 0.02006571]\n",
      " [0.02237038 0.12036026 0.15185152 0.01995911 0.0020597  0.06189092\n",
      "  0.0269219  0.14377189 0.04723367 0.06027987 0.00725451 0.01243648\n",
      "  0.01254815 0.03610086 0.03335752 0.02815148 0.01307184 0.02181175\n",
      "  0.05490839 0.12365981]\n",
      " [0.1339422  0.024477   0.00455591 0.04273033 0.00204361 0.01373508\n",
      "  0.08140083 0.05766259 0.01686894 0.0189508  0.06690101 0.01912696\n",
      "  0.04780746 0.06078091 0.01031403 0.13625614 0.03994136 0.10154942\n",
      "  0.10385837 0.01709702]\n",
      " [0.01664236 0.01912084 0.16201779 0.1958671  0.12122416 0.0315703\n",
      "  0.01135486 0.02081415 0.01048253 0.03808502 0.064602   0.01683129\n",
      "  0.04551661 0.01593884 0.03036786 0.01366975 0.01599243 0.02226397\n",
      "  0.14021344 0.0074247 ]\n",
      " [0.0989776  0.02065883 0.07779507 0.00580626 0.04011901 0.28009307\n",
      "  0.04921303 0.02325609 0.046848   0.01680312 0.02143981 0.01429793\n",
      "  0.11821247 0.02141621 0.0366888  0.07170399 0.02322708 0.01619856\n",
      "  0.01498698 0.0022581 ]] (5, 20)\n",
      "tensor([[0.0962, 0.0592, 0.1139, 0.0441, 0.0134, 0.0251, 0.0755, 0.0420, 0.0080,\n",
      "         0.0278, 0.0363, 0.0124, 0.0070, 0.0629, 0.1564, 0.0489, 0.0178, 0.1041,\n",
      "         0.0292, 0.0201],\n",
      "        [0.0224, 0.1204, 0.1519, 0.0200, 0.0021, 0.0619, 0.0269, 0.1438, 0.0472,\n",
      "         0.0603, 0.0073, 0.0124, 0.0125, 0.0361, 0.0334, 0.0282, 0.0131, 0.0218,\n",
      "         0.0549, 0.1237],\n",
      "        [0.1339, 0.0245, 0.0046, 0.0427, 0.0020, 0.0137, 0.0814, 0.0577, 0.0169,\n",
      "         0.0190, 0.0669, 0.0191, 0.0478, 0.0608, 0.0103, 0.1363, 0.0399, 0.1015,\n",
      "         0.1039, 0.0171],\n",
      "        [0.0166, 0.0191, 0.1620, 0.1959, 0.1212, 0.0316, 0.0114, 0.0208, 0.0105,\n",
      "         0.0381, 0.0646, 0.0168, 0.0455, 0.0159, 0.0304, 0.0137, 0.0160, 0.0223,\n",
      "         0.1402, 0.0074],\n",
      "        [0.0990, 0.0207, 0.0778, 0.0058, 0.0401, 0.2801, 0.0492, 0.0233, 0.0468,\n",
      "         0.0168, 0.0214, 0.0143, 0.1182, 0.0214, 0.0367, 0.0717, 0.0232, 0.0162,\n",
      "         0.0150, 0.0023]]) torch.Size([5, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2477333/2331782141.py:2: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  print(torch.nn.functional.softmax(m_t), torch.nn.functional.softmax(m_t).shape)\n"
     ]
    }
   ],
   "source": [
    "print(jax.nn.softmax(m_j), jax.nn.softmax(m_j).shape)\n",
    "print(torch.nn.functional.softmax(m_t), torch.nn.functional.softmax(m_t).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.2307962   0.7448285   1.399479    0.4502343  -0.738269   -0.1115755\n",
      "  0.9881029   0.40166688 -1.2604473  -0.01198584  0.25700086 -0.82012564\n",
      " -1.3902084   0.80530995  1.7168697   0.5534595  -0.45396855  1.3101196\n",
      "  0.03944339 -0.33643502 -0.17440483  1.508347    1.7407608  -0.28845635\n",
      " -2.5595796   0.8432311   0.01079767  1.6860855   0.57296455  0.8168558\n",
      " -1.3005195  -0.7615087  -0.75256944  0.3041742   0.22514082  0.05545757\n",
      " -0.71168226 -0.19969349  0.72352386  1.5353919   1.115256   -0.5844185\n",
      " -2.2657268  -0.02724335 -3.067434   -1.1621993   0.6172331   0.27245623\n",
      " -0.9566787  -0.84030616  0.42106158 -0.8310534   0.08502939  0.32512328\n",
      " -1.4486474   1.1323841  -0.09474019  0.8383931   0.8608758  -0.9432481\n",
      " -0.79755265 -0.65872484  1.4782022   1.6679324   1.1881374  -0.1572871\n",
      " -1.1798577  -0.5738708  -1.259794    0.03031707  0.55874133 -0.78626436\n",
      "  0.20857322 -0.8407454  -0.19611928 -0.9943184  -0.83738875 -0.5065345\n",
      "  1.3336619  -1.6046915   1.4425156  -0.1242352   1.2017002  -1.3934419\n",
      "  0.5394723   2.482744    0.74378043 -0.00581072  0.6945305  -0.33081374\n",
      " -0.08712813 -0.49226308  1.6201056  -0.08822985  0.45009345  1.1201684\n",
      " -0.00705918 -0.3674558  -0.44519636 -2.3378525 ] (100,)\n",
      "tensor([ 1.2308,  0.7448,  1.3995,  0.4502, -0.7383, -0.1116,  0.9881,  0.4017,\n",
      "        -1.2604, -0.0120,  0.2570, -0.8201, -1.3902,  0.8053,  1.7169,  0.5535,\n",
      "        -0.4540,  1.3101,  0.0394, -0.3364, -0.1744,  1.5083,  1.7408, -0.2885,\n",
      "        -2.5596,  0.8432,  0.0108,  1.6861,  0.5730,  0.8169, -1.3005, -0.7615,\n",
      "        -0.7526,  0.3042,  0.2251,  0.0555, -0.7117, -0.1997,  0.7235,  1.5354,\n",
      "         1.1153, -0.5844, -2.2657, -0.0272, -3.0674, -1.1622,  0.6172,  0.2725,\n",
      "        -0.9567, -0.8403,  0.4211, -0.8311,  0.0850,  0.3251, -1.4486,  1.1324,\n",
      "        -0.0947,  0.8384,  0.8609, -0.9432, -0.7976, -0.6587,  1.4782,  1.6679,\n",
      "         1.1881, -0.1573, -1.1799, -0.5739, -1.2598,  0.0303,  0.5587, -0.7863,\n",
      "         0.2086, -0.8407, -0.1961, -0.9943, -0.8374, -0.5065,  1.3337, -1.6047,\n",
      "         1.4425, -0.1242,  1.2017, -1.3934,  0.5395,  2.4827,  0.7438, -0.0058,\n",
      "         0.6945, -0.3308, -0.0871, -0.4923,  1.6201, -0.0882,  0.4501,  1.1202,\n",
      "        -0.0071, -0.3675, -0.4452, -2.3379]) torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "print(jnp.concatenate(list(m_j), axis=0), jnp.concatenate(list(m_j), axis=0).shape)\n",
    "print(torch.cat(list(m_t), dim=0), torch.cat(list(m_t), dim=0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_j.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([-3.3394163, 21.757278 , 73.084274 ,  6.2489467, 13.063147 ],      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optax.kl_divergence(m_j, m_j**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(22.1628)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.kl_div(m_t, m_t**2, reduction=\"none\").sum(dim=-1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(22.1628)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.kl_div(m_t, m_t**2, reduction=\"batchmean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.141592653589793"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-0.12078223763524526)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.special.gammaln(1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1447)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(torch.tensor(torch.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.1447298858494002)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# on GPU\n",
    "x = jnp.array([-1, 0, 1])\n",
    "print(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CudaDevice(id=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.log(sp.special.erfc(jnp.array([-1, 0, 1]))).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.6112, -1.3649, -0.8496], device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(torch.special.erfcx(torch.tensor([-1, 2, 1], device=\"cuda\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  1.0000, -0.2652,  1.0000, -5.8456, -1.5607, -0.8628, -0.9190,\n",
       "        -2.5656,  1.0000])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(x_t < 0, 1, torch.log(torch.special.erfcx(x_t)) - x_t**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.3205, -0.1476,  0.1481, -0.2243,  1.4895,  0.6268,  0.4015,  0.4218,\n",
       "         0.8846, -0.8532], device='cuda:0')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t.cuda() / np.sqrt(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sqrt(): argument 'input' (position 1) must be Tensor, not float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3.\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: sqrt(): argument 'input' (position 1) must be Tensor, not float"
     ]
    }
   ],
   "source": [
    "torch.sqrt(3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/jax311/lib/python3.11/site-packages/torch/_tensor.py:1194\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "abs(torch.tensor(1., device=\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2.], device='cuda:0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([torch.tensor(1., device=\"cuda\"), torch.tensor(2., device=\"cuda\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(x_t.cuda() > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.8675, 0.2087, 0.2095, 0.3172, 2.1064, 0.8864, 0.5678, 0.5965, 1.2510,\n",
       "        1.2066], device='cuda:0')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(x_t.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch._VariableFunctionsClass.logsumexp>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.logsumexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.8675, -0.2087,  0.0439, -0.3172,  2.1064,  0.7858,  0.3224,  0.3558,\n",
       "         1.2510, -1.2066])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.minimum(x_t, x_t**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([-1.8674781 , -0.20868118,  0.04387966, -0.31723955,  2.106423  ,\n",
       "        0.7857765 ,  0.32240006,  0.35580242,  1.2509658 , -1.2066083 ],      dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.minimum(x_j, x_j**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0439, 0.0000, 2.1064, 0.7858, 0.3224, 0.3558, 1.2510,\n",
       "        0.0000], device='cuda:0')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.clip(x_t.cuda(), torch.zeros_like(x_t.cuda()), x_t.cuda()**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.2095, 0.0000, 2.1064, 0.8864, 0.5678, 0.5965, 1.2510,\n",
       "        0.0000], device='cuda:0')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.clip(x_t.cuda(), torch.zeros_like(x_t.cuda()), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_j = jnp.array([[1., 3.], [3., 4.]])\n",
    "H_t = torch.tensor([[1., 3.], [3., 4.]], device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.854102   5.8541026]\n",
      "[[ 0.85065085  0.52573115]\n",
      " [-0.52573115  0.85065085]]\n",
      "tensor([-0.8541,  5.8541], device='cuda:0')\n",
      "tensor([[ 0.8507,  0.5257],\n",
      "        [-0.5257,  0.8507]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "evals, evecs = jnp.linalg.eigh(H_j)\n",
    "print(evals)\n",
    "print(evecs)\n",
    "evals, evecs = torch.linalg.eigh(H_t)\n",
    "print(evals)\n",
    "print(evecs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(3.5492759, dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.linalg.norm(x_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.5493, device='cuda:0')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(x_t.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.outer(x_t.cuda(), x_t.cuda()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.6466, 5.1045, 4.7594, 4.1404, 3.0992], device='cuda:0')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.svdvals(m_t.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.47712125, 0.53521889, 0.59331653, 0.65141417, 0.70951181,\n",
       "       0.76760945, 0.82570708, 0.88380472, 0.94190236, 1.        ])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(np.log10(3), np.log10(10), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 2, 2, 2, 1, 1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([np.linspace(np.log10(3), np.log10(10), 10), np.linspace(np.log10(1000), np.log10(3), 10)]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([inf, inf, inf, inf, inf, inf, inf, inf, inf, inf], device='cuda:0')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.inf * torch.ones(10, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.stack([torch.sum(x_t.cuda())]*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t[:, None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.8675, -1.8675],\n",
       "        [-0.2087, -0.2087],\n",
       "        [ 0.2095,  0.2095],\n",
       "        [-0.3172, -0.3172],\n",
       "        [ 2.1064,  2.1064],\n",
       "        [ 0.8864,  0.8864],\n",
       "        [ 0.5678,  0.5678],\n",
       "        [ 0.5965,  0.5965],\n",
       "        [ 1.2510,  1.2510],\n",
       "        [-1.2066, -1.2066]], device='cuda:0')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([x_t.cuda(), x_t.cuda()], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def unit(v, **kwargs):\n",
    "    return v / torch.norm(v, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unit(m_t.cuda(), dim=1, keepdim=True).norm(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.9269,  1.4873],\n",
      "        [ 0.9007, -2.1055],\n",
      "        [-0.7581,  1.0783],\n",
      "        [ 0.8008,  1.6806],\n",
      "        [ 0.3559, -0.6866],\n",
      "        [-0.4934,  0.2415],\n",
      "        [-0.2316,  0.0418],\n",
      "        [-0.2516,  0.8599],\n",
      "        [-0.3097, -0.3957],\n",
      "        [ 0.8034, -0.6216]])\n",
      "tensor([[ 0.3189, -0.4245],\n",
      "        [ 0.3057, -0.7746],\n",
      "        [-0.8371, -0.9224],\n",
      "        [ 1.8113,  0.1606],\n",
      "        [ 0.3672,  0.1754],\n",
      "        [ 1.3852, -0.4459],\n",
      "        [-1.2024,  0.7078],\n",
      "        [-1.0759,  0.5357],\n",
      "        [ 1.1754,  0.5612],\n",
      "        [-0.4527, -0.7718]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "print(torch.randn(10, 2))\n",
    "print(torch.randn(10, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1000000.6875)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.logsumexp(torch.tensor([1_000_000., 999_999.99]), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(1000000.7, dtype=float32)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.scipy.special.logsumexp(jnp.array([1_000_000., 999_999.99]), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Union\n",
    "\n",
    "def weighted_logsumexp(\n",
    "    logx: torch.Tensor,\n",
    "    w: torch.Tensor,\n",
    "    dim: int,\n",
    "    keepdim: bool = False,\n",
    "    return_sign: bool = False,\n",
    ") -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n",
    "    \"\"\"\n",
    "    from https://github.com/PhilippDahlinger/torch_weighted_logsumexp\n",
    "    \n",
    "    This is a Pytorch port of the Tensorflow function `reduce_weighted_logsumexp` from\n",
    "    https://www.tensorflow.org/probability/api_docs/python/tfp/math/reduce_weighted_logsumexp\n",
    "    Computes log(abs(sum(weight * exp(elements across tensor dimensions)))) in a numerically stable way.\n",
    "    Right now, it only supports to perform the operation over 1 dimension. (mandatory parameter)\n",
    "    :param logx: Tensor to reduce\n",
    "    :param w: weights, has to be same shape as logx\n",
    "    :param dim: dimension to reduce\n",
    "    :param keep_dim: if True, retains reduced dimensions with length 1\n",
    "    :param return_sign: if True, return the sign of weight * exp(elements across tensor dimensions)))\n",
    "    :return: Either the reduced tensor or a tuple of the reduced tensor and the sign\n",
    "    \"\"\"\n",
    "    log_absw_x = logx + torch.log(torch.abs(w))\n",
    "    max_log_absw_x = torch.amax(log_absw_x, dim=dim, keepdim=True)\n",
    "    max_log_absw_x = torch.where(\n",
    "        torch.isinf(max_log_absw_x),\n",
    "        torch.zeros(torch.Size([]), dtype=max_log_absw_x.dtype, device=max_log_absw_x.device),\n",
    "        max_log_absw_x)\n",
    "    wx_over_absw_x = torch.sign(w) * torch.exp(log_absw_x - max_log_absw_x)\n",
    "    sum_wx_over_max_absw_x = torch.sum(wx_over_absw_x, dim=dim, keepdim=keepdim)\n",
    "    if not keepdim:\n",
    "        max_log_absw_x = torch.squeeze(max_log_absw_x, dim=dim)\n",
    "    sgn = torch.sign(sum_wx_over_max_absw_x)\n",
    "    lswe = max_log_absw_x + torch.log(sgn * sum_wx_over_max_absw_x)\n",
    "    if return_sign:\n",
    "        return lswe, sgn\n",
    "    else:\n",
    "        return lswe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr_t = torch.randn(10, 2).cuda()\n",
    "rr_j = jax.dlpack.from_dlpack(rr_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.7189,  0.8785, -0.0223, -1.1490, -0.0799,  0.0048, -0.9557, -0.5013,\n",
       "         1.1053, -0.3878], device='cuda:0')"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_logsumexp(rr_t, \n",
    "                   torch.tensor([1., -1.], device=\"cuda\"), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.9764,  0.6442, -0.1470,  0.0365, -0.1549,  0.0823,  0.5257,  0.0992,\n",
       "         0.6928,  0.6979], device='cuda:0')"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_logsumexp(rr_t, w=torch.ones_like(rr_t)/2, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.5413248546129181)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+np.log(1-1/np.exp(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[-0.02830462,  0.46713185],\n",
       "       [ 0.29570296,  0.15354592],\n",
       "       [-0.12403282,  0.21692315],\n",
       "       [-1.4408789 ,  0.7558599 ],\n",
       "       [ 0.52140963,  0.9101704 ],\n",
       "       [-0.3844966 ,  1.1398233 ],\n",
       "       [ 1.4457862 ,  1.0809066 ],\n",
       "       [-0.05629321,  0.9095945 ],\n",
       "       [ 0.55734617,  0.21905719],\n",
       "       [-1.4485087 ,  0.7641875 ]], dtype=float32)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.random.normal(key=jax.random.PRNGKey(42), shape=(10, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([ 0.97643006,  0.6441725 , -0.14702275,  0.036503  , -0.154903  ,\n",
       "        0.08230504,  0.525661  ,  0.09921877,  0.6927911 ,  0.6979144 ],      dtype=float32)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.scipy.special.logsumexp(rr_j,\n",
    "                      b=1/2,\n",
    "                      axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pi - torch.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0689,  0.9299,  0.9294,  0.8425,  0.0496,  0.1254,  0.5479,  0.5093,\n",
       "        -0.1805, -0.1595], device='cuda:0')"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sinc(x_t.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.06893069,  0.92989045,  0.9293678 ,  0.8424823 ,  0.04958704,\n",
       "        0.12540717,  0.54792935,  0.50930524, -0.18046935, -0.15945804],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sinc(x_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([-0.06893069,  0.92989045,  0.9293678 ,  0.8424823 ,  0.04958703,\n",
       "        0.12540717,  0.54792935,  0.50930524, -0.18046935, -0.15945804],      dtype=float32)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.sinc(x_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[194], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(x_t\u001b[38;5;241m.\u001b[39mcuda()) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m3\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert max(x_t.cuda()) > 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
